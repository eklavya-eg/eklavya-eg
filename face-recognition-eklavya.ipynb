{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7514479,"sourceType":"datasetVersion","datasetId":4376972}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install cloud-tpu-client==0.10 torch==1.12.0 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-1.12-cp37-cp37m-linux_x86_64.whl\nimport torch\nimport torch_xla\nimport torch_xla.core.xla_model as xm\ndevice = xm.xla_device()\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T22:18:06.897024Z","iopub.execute_input":"2024-01-30T22:18:06.897305Z","iopub.status.idle":"2024-01-30T22:18:39.508939Z","shell.execute_reply.started":"2024-01-30T22:18:06.897276Z","shell.execute_reply":"2024-01-30T22:18:39.508038Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: torch_xla-1.12-cp37-cp37m-linux_x86_64.whl is not a supported wheel on this platform.\u001b[0m\u001b[31m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n","output_type":"stream"},{"name":"stdout","text":"xla:0\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport random\n\nclass DataBuilder:\n    def __init__(self, in_path, labels_72, labels_5):\n        self.data = []\n        for ldir in os.listdir(in_path):\n            total = 0\n            if \"72\" in ldir : limit = labels_72\n            elif \"5\" in ldir : limit = labels_5\n            for individuals in os.listdir(os.path.join(in_path, ldir)):\n                if total<limit:\n                    labels = os.listdir(os.path.join(in_path, ldir))\n                    labels = list(set(labels)-{individuals})\n                    random.shuffle(labels)\n                    images = os.listdir(os.path.join(in_path, ldir, individuals))\n                    anchor = \"0.png\"\n                    images = list(set(images)-{anchor})\n                    anchor = \"/\".join([in_path, ldir, individuals, anchor])\n                    for i in range(len(images)):\n                        pos = \"/\".join([in_path, ldir, individuals, images[i]])\n                        if i != 0:\n                            label = os.listdir(os.path.join(in_path, ldir, labels[i]))\n                            random.shuffle(label)\n                            label = label[0]\n                            neg = \"/\".join([in_path, ldir, labels[i], label])\n                        else:\n                            label = os.listdir(os.path.join(in_path, ldir, labels[i]))[0]\n                            neg = \"/\".join([in_path, ldir, labels[i], label])\n                        self.data.append([anchor, pos, neg])\n                    total += 1\n\n\npath = \"/kaggle/input/face-recognition\"\n# path = \"/\".join(path)\ndata = DataBuilder(path, 1000, 1000)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T22:18:39.510625Z","iopub.execute_input":"2024-01-30T22:18:39.511032Z","iopub.status.idle":"2024-01-30T22:20:55.179356Z","shell.execute_reply.started":"2024-01-30T22:18:39.510998Z","shell.execute_reply":"2024-01-30T22:20:55.178502Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import random\ndata = data.data\nrandom.shuffle(data)\nfor i in data[:5]:\n    print(i)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T22:20:55.180409Z","iopub.execute_input":"2024-01-30T22:20:55.180691Z","iopub.status.idle":"2024-01-30T22:20:55.228393Z","shell.execute_reply.started":"2024-01-30T22:20:55.180666Z","shell.execute_reply":"2024-01-30T22:20:55.227647Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"['/kaggle/input/face-recognition/subjects_0-1999_72_imgs/1601/0.png', '/kaggle/input/face-recognition/subjects_0-1999_72_imgs/1601/69.png', '/kaggle/input/face-recognition/subjects_0-1999_72_imgs/1261/68.png']\n['/kaggle/input/face-recognition/subjects_0-1999_72_imgs/1433/0.png', '/kaggle/input/face-recognition/subjects_0-1999_72_imgs/1433/59.png', '/kaggle/input/face-recognition/subjects_0-1999_72_imgs/584/3.png']\n['/kaggle/input/face-recognition/subjects_0-1999_72_imgs/105/0.png', '/kaggle/input/face-recognition/subjects_0-1999_72_imgs/105/40.png', '/kaggle/input/face-recognition/subjects_0-1999_72_imgs/330/17.png']\n['/kaggle/input/face-recognition/subjects_0-1999_72_imgs/1152/0.png', '/kaggle/input/face-recognition/subjects_0-1999_72_imgs/1152/58.png', '/kaggle/input/face-recognition/subjects_0-1999_72_imgs/1164/21.png']\n['/kaggle/input/face-recognition/subjects_100000-133332_5_imgs/112573/0.png', '/kaggle/input/face-recognition/subjects_100000-133332_5_imgs/112573/3.png', '/kaggle/input/face-recognition/subjects_100000-133332_5_imgs/105091/3.png']\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.io import read_image, ImageReadMode\nfrom sklearn.model_selection import train_test_split\n\nclass FaceDataset(Dataset):\n    def __init__(self, data):\n        self.data = data\n    \n    def __getitem__(self, index):\n        anchor, positive, negative = self.data[index]\n        anchor = read_image(anchor, mode=ImageReadMode.RGB)\n        positive = read_image(positive, mode=ImageReadMode.RGB)\n        negative = read_image(negative, mode=ImageReadMode.RGB)\n        return torch.as_tensor(anchor, dtype=torch.float32), torch.as_tensor(positive, dtype=torch.float32), torch.as_tensor(negative, dtype=torch.float32)\n    \n    def __len__(self):\n        return len(self.data)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T22:44:41.891562Z","iopub.execute_input":"2024-01-30T22:44:41.891984Z","iopub.status.idle":"2024-01-30T22:44:41.898568Z","shell.execute_reply.started":"2024-01-30T22:44:41.891951Z","shell.execute_reply":"2024-01-30T22:44:41.897808Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn as nn\nfrom torch import optim as optim\nfrom torch.nn import functional as F\nfrom torch.optim import lr_scheduler\nclass Model(nn.Module):\n    def __init__(self, in_channels, embedding_size, batch_size):\n        super(Model, self).__init__()\n        self.conv = nn.Sequential(nn.Conv2d(in_channels, in_channels, kernel_size=1, padding=0),\n                                   nn.AvgPool2d(kernel_size=2, stride=2))\n        \n\n        self.b1 = nn.Conv2d(3, 64, kernel_size=1, padding=\"same\")\n        self.b2 = nn.Sequential(nn.Conv2d(in_channels, 92, kernel_size=1, padding=\"same\"),\n                                nn.Conv2d(92, 128, kernel_size=3, padding=\"same\"))\n        self.b3 = nn.Sequential(nn.Conv2d(in_channels, 24, kernel_size=1, padding=\"same\"),\n                                nn.Conv2d(24, 32, kernel_size=5, padding=\"same\"))\n        self.b4 = nn.Sequential(nn.MaxPool2d(kernel_size=3, padding=1, stride = 1),\n                                nn.Conv2d(in_channels, 32, kernel_size=1, padding=\"same\"))\n        \n\n        self.b5 = nn.Conv2d(256, 32, kernel_size=1, padding=\"same\")\n        self.b6 = nn.Sequential(nn.Conv2d(256, 128, kernel_size=1, padding=\"same\"),\n                                nn.Conv2d(128, 64, kernel_size=3, padding=\"same\"))\n        self.b7 = nn.Sequential(nn.Conv2d(256, 24, kernel_size=1, padding=\"same\"),\n                                nn.Conv2d(24, 16, kernel_size=5, padding=\"same\"))\n        self.b8 = nn.Sequential(nn.MaxPool2d(kernel_size=3, padding=1, stride = 1),\n                                nn.Conv2d(256, 16, kernel_size=1, padding=\"same\"))\n\n        self.b5 = nn.Conv2d(256, 32, kernel_size=1, padding=\"same\")\n        self.b6 = nn.Sequential(nn.Conv2d(256, 128, kernel_size=1, padding=\"same\"),\n                                nn.Conv2d(128, 64, kernel_size=3, padding=\"same\"))\n        self.b7 = nn.Sequential(nn.Conv2d(256, 24, kernel_size=1, padding=\"same\"),\n                                nn.Conv2d(24, 16, kernel_size=5, padding=\"same\"))\n        self.b8 = nn.Sequential(nn.MaxPool2d(kernel_size=3, padding=1, stride = 1),\n                                nn.Conv2d(256, 16, kernel_size=1, padding=\"same\"))\n        \n        self.fc = nn.Sequential(nn.Linear(401408, 512, bias=True),\n                                nn.Linear(512, embedding_size, bias=True))\n        \n        self.batch_size = batch_size\n        \n    def forward(self, x):\n        x = self.conv(x)\n\n        xb1 = self.b1(x)\n        xb2 = self.b2(x)\n        xb3 = self.b3(x)\n        xb4 = self.b4(x)\n        x = torch.cat([xb1, xb2, xb3, xb4], dim = 1)\n\n        xb5 = self.b5(x)\n        xb6 = self.b6(x)\n        xb7 = self.b7(x)\n        xb8 = self.b8(x)\n        x = torch.cat([xb5, xb6, xb7, xb8], dim = 1)\n\n        x = x.view(self.batch_size, -1)\n        x = self.fc(x)\n\n        return x\n\nclass TripletLoss:\n    def __init__(self, margin, p):\n        self.margin = margin\n        self.p = p\n\n    def loss(self, anchor, positive, negative):\n        distance_ap = F.pairwise_distance(anchor, positive, p = self.p)\n        distance_an = F.pairwise_distance(anchor, negative, p = self.p)\n        tripletloss = torch.clamp(input=distance_ap+(self.margin)-distance_an, min=0.0).mean()\n        return tripletloss\n\nclass Optimizer:\n    def __init__(self, model, lr):\n        self.model = model\n        self.lr = lr\n    \n    def optimize(self):\n        return optim.Adam(self.model.parameters(), lr=self.lr)\n\nclass Schedular:\n    def __init__(self, optimizer, lr, step_size, gamma):\n        self.optimizer = optimizer\n        self.lr = lr\n        self.step_size = step_size\n        self.gamma = gamma\n    \n    def decay(self):\n        return lr_scheduler.StepLR(self.optimizer, self.step_size, self.gamma)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Variables:\n    def __init__(self, in_channels=3, embedding_size=256, batch_size=50, batch_size_test_val = 50, lr=0.001, margin=0.2, p=2, epochs=100, step_size=30, gamma=0.1):\n        self.batch_size = batch_size\n        self.lr = lr\n        self.in_channels = in_channels\n        self.emembedding_size =embedding_size\n        self.p = p\n        self.margin = margin\n        self.epochs = epochs\n        self.step_size = step_size\n        self.gamma = gamma\n        self.batch_size_test_val = batch_size_test_val\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport warnings\nfrom tqdm import tqdm\nimport torch\nfrom torch import nn as nn\nfrom torch import optim as optim\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\n\n\nif __name__ == \"__main__\":\n    # warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.nn.init\")\n\n\n    train = data[0:70000]\n    val = data[70000:72000]\n    test = data[72000:75000]\n    \n\n    train = FaceDataset(train)\n    val = FaceDataset(val)\n    test = FaceDataset(test)\n    variables = Variables()\n    train = DataLoader(train, batch_size = variables.batch_size, shuffle=False)\n    val = DataLoader(val, batch_size = variables.batch_size_test_val, shuffle=False)\n    test = DataLoader(test, batch_size = variables.batch_size_test_val, shuffle=False)\n\n    print(len(train))\n    print(len(val))\n    print(len(test))\n    \n    \n    \n    model = Model(in_channels=variables.in_channels, embedding_size=variables.emembedding_size, batch_size=variables.batch_size)\n    tripletloss = TripletLoss(margin=variables.margin, p=variables.p)\n    optimizer = Optimizer(model=model, lr=variables.lr).optimize()\n    schedular = Schedular(optimizer, variables.lr, variables.step_size, variables.gamma).decay()\n    device = \"cuda\"\n    device = xm.xla_device()\n    model.to(device)\n\n    for epoch in range(0, variables.epochs):\n        model.train()\n        train_cost = 0.0\n        loop = tqdm(enumerate(train), total=len(train), leave=True)\n        for _, train_batch in loop:\n            anc, pos, neg = train_batch\n            anc, pos, neg = anc.to(device), pos.to(device), neg.to(device)\n            anc = model.forward(anc)\n            pos = model.forward(pos)\n            neg = model.forward(neg)\n            loss = tripletloss.loss(anc, pos, neg)\n            train_cost += loss\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            loop.set_description(f\"[{epoch+1}/{variables.epochs}]\")\n            loop.set_postfix(loss=loss.item())\n        avg_train_loss = train_cost/len(train)\n        \n        model.eval()\n        with torch.no_grad():\n            val_cost = 0.0\n            loop_val = tqdm(enumerate(val), total=len(val), leave=True)\n            for _, val_batch in loop_val:\n                anc, pos, neg = val_batch\n                anc, pos, neg = anc.to(device), pos.to(device), neg.to(device)\n                anc = model.forward(anc)\n                pos = model.forward(pos)\n                neg = model.forward(neg)\n                val_loss = tripletloss.loss(anc, pos, neg)\n                val_cost += val_loss.item()\n                loop_val.set_description(f\"[{epoch+1}/{variables.epochs}]\")\n                loop_val.set_postfix(loss=val_loss.item())\n            avg_val_loss = val_cost/len(val)\n            print(f\"Epoch {epoch+1}/{variables.epochs}, Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}\")\n        checkpoint_filename = f\"model_epoch_{epoch+1}.pth\"\n        if avg_train_loss < 100:\n            torch.save(model.state_dict(), checkpoint_filename)\n        schedular.step()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\ntorch.cuda.empty_cache()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-30T22:46:50.131986Z","iopub.execute_input":"2024-01-30T22:46:50.132396Z","iopub.status.idle":"2024-01-30T22:46:50.136519Z","shell.execute_reply.started":"2024-01-30T22:46:50.132364Z","shell.execute_reply":"2024-01-30T22:46:50.135737Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch_xla\nimport torch_xla.core.xla_model as xm\nxm.rendezvous('clear_memory')  # This can help clear TPU memory\n","metadata":{"execution":{"iopub.status.busy":"2024-01-30T22:47:22.526721Z","iopub.execute_input":"2024-01-30T22:47:22.527288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}